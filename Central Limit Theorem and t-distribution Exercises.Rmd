---
title: "R Notebook_Central Limit Theorem and t-distribution Exercise"
output: html_notebook
---

Importing data into R 

```{r}
library(downloader) 
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/mice_pheno.csv"
filename <- basename(url)
download(url, destfile=filename)
dat <- na.omit( read.csv(filename) )
head(dat)
```
1. If a list of numbers has a distribution that is well approximated by the normal distribution, what proportion of these numbers are within one standard deviation away from the list’s average?

2. What proportion of these numbers are within two standard deviations away from the list’s average?

3. What proportion of these numbers are within three standard deviations away from the list’s average?

```{r}
list_mean <- mean(dat$Bodyweight)
list_sd <- sd(dat$Bodyweight)

num_std_devs <- c(1, 2, 3)


proportions <- numeric(length(num_std_devs))

for (i in 1:length(num_std_devs)) {
  lower_bound <- list_mean - num_std_devs[i] * list_sd
  upper_bound <- list_mean + num_std_devs[i] * list_sd
  proportions[i] <- length(dat$Bodyweight[dat$Bodyweight >= lower_bound & dat$Bodyweight <= upper_bound]) / length(dat$Bodyweight)
}

for (i in 1:length(num_std_devs)) {
  cat("Proportion of numbers within", num_std_devs[i], "standard deviations from the mean:", proportions[i], "\n")
}
```
4. Define y to be the weights of males on the control diet. What proportion of the mice are within one standard deviation away from the average weight (remember to use popsd for the population sd)?

5. What proportion of these numbers are within two standard deviations away from the list’s average?

6. What proportion of these numbers are within three standard deviations away from the list’s average?
```{r}
y <- dat$Bodyweight[dat$Sex == "M" & dat$Diet == "chow"]


list_mean <- mean(y)
list_pop_sd <- popsd(y)

num_std_devs <- c(1, 2, 3)


proportions <- numeric(length(num_std_devs))

for (i in 1:length(num_std_devs)) {
  lower_bound <- list_mean - num_std_devs[i] * list_pop_sd
  upper_bound <- list_mean + num_std_devs[i] * list_pop_sd
  proportions[i] <- length(y[y >= lower_bound & y <= upper_bound]) / length(y)
}

for (i in 1:length(num_std_devs)) {
  cat("Proportion of male mice on the control diet within", num_std_devs[i], "standard deviations from the mean weight:", proportions[i], "\n")
}
```
7.Note that the numbers for the normal distribution and our weights are relatively close. Also, notice that we are indirectly comparing quantiles of the normal distribution to quantiles of the mouse weight distribution. We can actually compare all quantiles using a qqplot.
```{r}
qqnorm(y)
qqline(y)

title("QQ-Plot of Mouse Weights vs. Normal Distribution")

```
8.Create the above qq-plot for the four populations: male/females on each of the two diets. What is the most likely explanation for the mouse weights being well approximated? What is the best explanation for all these being well approximated by the normal distribution?
```{r}
male_chow<-dat$Bodyweight[dat$Sex=="M" & dat$Diet=="chow"]
female_chow<-dat$Bodyweight[dat$Sex=="F" & dat$Diet=="chow"]
male_hf<-dat$Bodyweight[dat$Sex=="M" & dat$Diet=="hf"]
female_hf<-dat$Bodyweight[dat$Sex=="F" & dat$Diet=="hf"]

par(mfrow = c(2, 2))

qqnorm(male_chow, main = "Male on Chow Diet")
qqline(male_chow)

qqnorm(female_chow, main = "Female on Chow Diet")
qqline(female_chow)

qqnorm(male_hf, main = "Male on hf Diet")
qqline(male_hf)

qqnorm(female_hf, main = "Female on hf Diet")
qqline(female_hf)


par(mfrow = c(1, 1))

title("QQ-Plots of Mouse Weights vs. Normal Distribution")
```
9. We will now take a sample of size 25 from the population of males on the chow diet. The average of this sample is our random variable. We will use the replicate to observe 10,000 realizations of this random variable. Set the seed at 1, generate these 10,000 averages. Make a histogram and qq-plot of these 10,000 numbers against the normal distribution.
```{r}
set.seed(1)
y<-filter(dat,Sex=="M" & Diet=="chow")$Bodyweight
avgs<-replicate(10000,mean(sample(y,25)))
mypar(1,2)
hist(avgs)
qqnorm(avgs)
qqline(avgs)
```
10. What is the average of the distribution of the sample average?

11. What is the standard deviation of the distribution of sample averages?
```{r}
average_of_sample_averages <- mean(avgs)

std_deviation_of_sample_averages <- sd(avgs)

cat("Average of the distribution of sample averages:", average_of_sample_averages, "\n")
cat("Standard deviation of the distribution of sample averages:", std_deviation_of_sample_averages, "\n")
```
12. In practice we do not know σ (popsd(y)) which is why we can’t use the CLT directly. This is because we see a sample and not the entire distribution. We also can’t use popsd(avgs) because to construct averages, we have to take 10,000 samples and this is never practical. We usually just get one sample. Instead we have to estimate popsd(y). As described, what we use is the sample standard deviation. Set the seed at 1, using the replicate function, create 10,000 samples of 25 and now, instead of the sample average, keep the standard deviation. Look at the distribution of the sample standard deviations. It is a random variable. The real population SD is about 4.5. What proportion of the sample SDs are below 3.5?
```{r}

set.seed(1)

sample_std_devs <- replicate(10000, sd(sample(y, 25)))
proportion_below_3.5 <- mean(sample_std_devs < 3.5)

cat("Proportion of sample standard deviations below 3.5:", proportion_below_3.5, "\n")

```

13. What the answer to question 12 reveals is that the denominator of the t-test is a random variable. By decreasing the sample size, you can see how this variability can increase. It therefore adds variability. The smaller the sample size, the more variability is added. The normal distribution stops providing a useful approximation. When the distribution of the population values is approximately normal, as it is for the weights, the t-distribution provides a better approximation. We will see this later on. Here we will look at the difference between the t-distribution and normal. Use the function qt and qnorm to get the quantiles of x=seq(0.0001,0.9999,len=300). Do this for degrees of freedom 3, 10, 30, and 100.

```{r}
x<-seq(0.0001, 0.9999, len = 300)
df<-c(3,10,30,100)

quantiles_t<-sapply(df,function(dof) qt(x,df=dof))
quantiles_normal<-qnorm(x)

for (i in 1:length(df)) {
  cat("Quantiles for degrees of freedom", df[i], "in the t-distribution:\n")
  cat(quantiles_t[, i], "\n")
  cat("Quantiles for degrees of freedom", df[i], "in the normal distribution:\n")
  cat(quantiles_normal, "\n\n")
}
```























